{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GameNet (Hartford et al 2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string as string\n",
    "from __future__ import division\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import_csv = pd.read_csv('gamesmxn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine same games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(1, import_csv.shape[0]):\n",
    "    if pd.DataFrame(import_csv['matrixrow'][0:i] == import_csv['matrixrow'][i]).values.any():\n",
    "        repeatmat = import_csv['matrixrow'][0:i][import_csv['matrixrow'][0:i] == import_csv['matrixrow'][i]].index[0]\n",
    "        choicesum = np.matrix(import_csv['choicerow'][repeatmat]) + np.matrix(import_csv['choicerow'][i])\n",
    "        choicesum = string.replace(str(choicesum),'[','')\n",
    "        choicesum = string.replace(str(choicesum),']]','')\n",
    "        choicesum = string.replace(str(choicesum),']\\n',';')\n",
    "        import_csv.set_value(repeatmat, 'choicerow', choicesum)\n",
    "        import_csv.drop([i], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select games to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp = np.empty((import_csv.shape[0]))\n",
    "tmp[:] = np.NAN\n",
    "for i in range(import_csv.shape[0]):\n",
    "    if (import_csv['shape'][i] == '3 3' \n",
    "        and import_csv['symmetric'][i] == 1 \n",
    "        and import_csv['paper'][i] != 'stahlwilson1995'):\n",
    "        tmp[i] = i\n",
    "index = tmp[~np.isnan(tmp)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs_row = np.zeros((index.shape[0], 3, 3, 2))\n",
    "inputs_col = np.zeros((index.shape[0], 3, 3, 2))\n",
    "target_row = np.zeros((index.shape[0], 3, 1))\n",
    "for j in range(index.shape[0]):\n",
    "    Ur = np.matrix(import_csv['matrixrow'][int(index[j])])\n",
    "    Ur = (Ur-np.mean(Ur))/np.std(Ur)\n",
    "    Uc = np.transpose(Ur)\n",
    "    ar = np.matrix(import_csv['choicerow'][int(index[j])])\n",
    "    if ar.shape[1] == 2:\n",
    "        ar = ar[:,0]/ar[:,1]\n",
    "    inputs_row[j, :, :, 0] = Ur\n",
    "    inputs_row[j, :, :, 1] = Uc\n",
    "    inputs_col[j, :, :, 0] = Uc\n",
    "    inputs_col[j, :, :, 1] = Ur\n",
    "    target_row[j] = ar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and test sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shuffle = np.random.permutation(range(inputs_row.shape[0]))\n",
    "index_train = shuffle[0:inputs_row.shape[0]//5*4] \n",
    "index_tests = shuffle[inputs_row.shape[0]//5*4:inputs_row.shape[0]]\n",
    "inputs_row_train = inputs_row[index_train]\n",
    "inputs_col_train = inputs_col[index_train]\n",
    "target_row_train = target_row[index_train]\n",
    "inputs_row_tests = inputs_row[index_tests]\n",
    "inputs_col_tests = inputs_col[index_tests]\n",
    "target_row_tests = target_row[index_tests]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weights and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolution and pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rw_pool(x,c):\n",
    "    x_max = tf.reduce_max(x, axis=2)\n",
    "    x_til = tf.tile(x_max,[1,3,1])\n",
    "    x_sha = tf.reshape(x_til,[-1,3,3,c])\n",
    "    return tf.transpose(x_sha, perm=[0,2,1,3])\n",
    "\n",
    "def cw_pool(x,c):\n",
    "    x_max = tf.reduce_max(x, axis=1)\n",
    "    x_til = tf.tile(x_max,[1,3,1])\n",
    "    return tf.reshape(x_til,[-1,3,3,c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_row = tf.placeholder(tf.float32, shape=[None, 3, 3, 2])\n",
    "x_col = tf.placeholder(tf.float32, shape=[None, 3, 3, 2])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 3, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden layer 1 (row player)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow version `0.12.1` uses `tf.concat(axis, values, name='concat')`, not `tf.concat(values, axis, name='concat')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_pool1 = tf.concat(3, [x_row, rw_pool(x_row, 2), cw_pool(x_row, 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W_conv1 = weight_variable([1, 1, 6, 50])\n",
    "b_conv1 = bias_variable([50])\n",
    "h_conv1 = tf.nn.relu(conv2d(x_pool1, W_conv1) + b_conv1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden layer 2 (row player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_pool2 = tf.concat(3, [h_conv1, rw_pool(h_conv1, 50), cw_pool(h_conv1, 50)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W_conv2 = weight_variable([1, 1, 150, 50])\n",
    "b_conv2 = bias_variable([50])\n",
    "h_conv2 = tf.nn.relu(conv2d(x_pool2, W_conv2) + b_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_conv2_drop = tf.nn.dropout(h_conv2, keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <h3> Hidden layer 1 (col player) </h3> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_pool1_col = tf.concat(3, [x_col, rw_pool(x_col, 2), cw_pool(x_col, 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_conv1_col = weight_variable([1, 1, 6, 50])\n",
    "b_conv1_col = bias_variable([50])\n",
    "h_conv1_col = tf.nn.relu(conv2d(x_pool1_col, W_conv1_col) + b_conv1_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <h3> Hidden layer 2 (col player) </h3> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_pool2_col = tf.concat(3, [h_conv1_col, rw_pool(h_conv1_col, 50), cw_pool(h_conv1_col, 50)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W_conv2_col = weight_variable([1, 1, 150, 50])\n",
    "b_conv2_col = bias_variable([50])\n",
    "h_conv2_col = tf.nn.relu(conv2d(x_pool2_col, W_conv2_col) + b_conv2_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep_prob_col = tf.placeholder(tf.float32)\n",
    "h_conv2_col_drop = tf.nn.dropout(h_conv2_col, keep_prob_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <h3> Action response layer 0 (col player) </h3> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_rwsm0 = weight_variable([1, 1, 50, 50])\n",
    "h_rdsm1 = conv2d(h_conv2_col_drop, W_rwsm0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ar_rwsm0_col = tf.reduce_sum(h_conv2_col_drop, axis=2)\n",
    "ar_sfmx0_col = tf.nn.softmax(ar_rwsm0_col, dim=1)\n",
    "ar_sfmx0_col = tf.slice(ar_sfmx0_col, [0, 0, 0], [-1, 3, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action response layer 1 (row player response to col player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_rdsm1 = weight_variable([1, 1, 50, 50])\n",
    "h_rdsm1 = conv2d(h_conv2_drop, W_rdsm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ar_rdsm1 = tf.reduce_sum(h_rdsm1, axis=3)\n",
    "ar_dtpt1 = tf.matmul(ar_rdsm1, ar_sfmx0_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = tf.nn.softmax(ar_dtpt1, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "beta = 0.01\n",
    "regularizer = (tf.nn.l2_loss(W_conv1) \n",
    "               + tf.nn.l2_loss(W_conv2) \n",
    "               + tf.nn.l2_loss(W_conv1_col) \n",
    "               + tf.nn.l2_loss(W_conv2_col)\n",
    "               + tf.nn.l2_loss(W_rwsm0) \n",
    "               + tf.nn.l2_loss(W_rdsm1))\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y) + beta * regularizer, reduction_indices=[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.AdamOptimizer(0.0002,0.9,0.999,1e-8).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, train accuracy 0.333333, train NLL -1.26428\n",
      "step 100, train accuracy 0.8, train NLL -2.32925\n",
      "step 200, train accuracy 0.8, train NLL -3.47916\n",
      "step 300, train accuracy 0.866667, train NLL -5.03307\n",
      "step 400, train accuracy 0.866667, train NLL -6.82405\n",
      "step 500, train accuracy 1, train NLL -9.19693\n",
      "step 600, train accuracy 0.933333, train NLL -11.846\n",
      "step 700, train accuracy 0.866667, train NLL -14.9005\n",
      "step 800, train accuracy 0.933333, train NLL -18.7021\n",
      "step 900, train accuracy 0.866667, train NLL -22.6127\n",
      "step 1000, train accuracy 1, train NLL -27.0295\n",
      "step 1100, train accuracy 1, train NLL -31.909\n",
      "step 1200, train accuracy 0.866667, train NLL -37.1212\n",
      "step 1300, train accuracy 1, train NLL -42.8654\n",
      "step 1400, train accuracy 0.933333, train NLL -48.9672\n",
      "step 1500, train accuracy 0.8, train NLL -55.4236\n",
      "step 1600, train accuracy 1, train NLL -62.5476\n",
      "step 1700, train accuracy 1, train NLL -69.712\n",
      "step 1800, train accuracy 1, train NLL -77.377\n",
      "step 1900, train accuracy 1, train NLL -85.5902\n",
      "step 2000, train accuracy 1, train NLL -94.0344\n",
      "step 2100, train accuracy 1, train NLL -102.837\n",
      "step 2200, train accuracy 1, train NLL -112.02\n",
      "step 2300, train accuracy 0.866667, train NLL -121.543\n",
      "step 2400, train accuracy 0.933333, train NLL -131.473\n",
      "step 2500, train accuracy 0.933333, train NLL -141.556\n",
      "step 2600, train accuracy 0.933333, train NLL -152.274\n",
      "step 2700, train accuracy 1, train NLL -163.156\n",
      "step 2800, train accuracy 1, train NLL -174.451\n",
      "step 2900, train accuracy 1, train NLL -185.909\n",
      "step 3000, train accuracy 0.933333, train NLL -197.679\n",
      "step 3100, train accuracy 1, train NLL -209.982\n",
      "step 3200, train accuracy 1, train NLL -222.461\n",
      "step 3300, train accuracy 1, train NLL -235.153\n",
      "step 3400, train accuracy 1, train NLL -248.435\n",
      "step 3500, train accuracy 0.933333, train NLL -261.645\n",
      "step 3600, train accuracy 0.933333, train NLL -275.462\n",
      "step 3700, train accuracy 1, train NLL -289.43\n",
      "step 3800, train accuracy 0.866667, train NLL -303.597\n",
      "step 3900, train accuracy 1, train NLL -318.313\n",
      "step 4000, train accuracy 0.8, train NLL -333.007\n",
      "step 4100, train accuracy 1, train NLL -348.113\n",
      "step 4200, train accuracy 0.933333, train NLL -363.564\n",
      "step 4300, train accuracy 0.933333, train NLL -379.119\n",
      "step 4400, train accuracy 1, train NLL -395.173\n",
      "step 4500, train accuracy 0.933333, train NLL -411.241\n",
      "step 4600, train accuracy 0.933333, train NLL -427.791\n",
      "step 4700, train accuracy 1, train NLL -444.504\n",
      "step 4800, train accuracy 0.8, train NLL -461.586\n",
      "step 4900, train accuracy 1, train NLL -478.709\n"
     ]
    }
   ],
   "source": [
    "for i in range(5000):\n",
    "    if i%5 == 0:\n",
    "        shuffle = np.random.permutation(range(inputs_row_train.shape[0]))\n",
    "    inputs_row_train_batch = inputs_row_train[shuffle[shuffle.shape[0]//5*(i%5):shuffle.shape[0]//5*(i%5+1)]]\n",
    "    inputs_col_train_batch = inputs_col_train[shuffle[shuffle.shape[0]//5*(i%5):shuffle.shape[0]//5*(i%5+1)]]\n",
    "    target_row_train_batch = target_row_train[shuffle[shuffle.shape[0]//5*(i%5):shuffle.shape[0]//5*(i%5+1)]]\n",
    "    if i%100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={\n",
    "                x_row: inputs_row_train_batch,\n",
    "                x_col: inputs_col_train_batch,\n",
    "                y_: target_row_train_batch, \n",
    "                keep_prob: 1.0,\n",
    "                keep_prob_col: 1.0})\n",
    "        train_NLL = cross_entropy.eval(feed_dict={\n",
    "                x_row: inputs_row_train_batch, \n",
    "                x_col: inputs_col_train_batch,\n",
    "                y_: target_row_train_batch,\n",
    "                keep_prob: 1.0,\n",
    "                keep_prob_col: 1.0})\n",
    "        print(\"step %d, train accuracy %g, train NLL %g\"%(i, train_accuracy, train_NLL))\n",
    "    train_step.run(feed_dict={x_row: inputs_row_train_batch, \n",
    "                              x_col: inputs_col_train_batch, \n",
    "                              y_: target_row_train_batch, \n",
    "                              keep_prob: 0.8,\n",
    "                              keep_prob_col: 0.8})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.9, test NLL -496.158\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = accuracy.eval(feed_dict={\n",
    "        x_row: inputs_row_tests,\n",
    "        x_col: inputs_col_tests,\n",
    "        y_: target_row_tests, \n",
    "        keep_prob: 1.0,\n",
    "        keep_prob_col: 1.0})\n",
    "test_NLL = cross_entropy.eval(feed_dict={\n",
    "        x_row: inputs_row_tests,\n",
    "        x_col: inputs_col_tests,\n",
    "        y_: target_row_tests, \n",
    "        keep_prob: 1.0,\n",
    "        keep_prob_col: 1.0})\n",
    "print(\"test accuracy %g, test NLL %g\"%(test_accuracy, test_NLL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>y3</th>\n",
       "      <th>y_1</th>\n",
       "      <th>y_2</th>\n",
       "      <th>y_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.011138</td>\n",
       "      <td>0.985176</td>\n",
       "      <td>3.685282e-03</td>\n",
       "      <td>0.027211</td>\n",
       "      <td>0.945578</td>\n",
       "      <td>0.027211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.590869</td>\n",
       "      <td>0.210588</td>\n",
       "      <td>1.985438e-01</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.843376</td>\n",
       "      <td>0.058791</td>\n",
       "      <td>9.783307e-02</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.186667</td>\n",
       "      <td>0.293333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.902462</td>\n",
       "      <td>0.023093</td>\n",
       "      <td>7.444493e-02</td>\n",
       "      <td>0.911565</td>\n",
       "      <td>0.027211</td>\n",
       "      <td>0.061224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.567337</td>\n",
       "      <td>0.044450</td>\n",
       "      <td>3.882132e-01</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.506667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.432438</td>\n",
       "      <td>0.166710</td>\n",
       "      <td>4.008521e-01</td>\n",
       "      <td>0.531915</td>\n",
       "      <td>0.297872</td>\n",
       "      <td>0.170213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.013056</td>\n",
       "      <td>0.986944</td>\n",
       "      <td>1.614471e-08</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.234043</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.049494</td>\n",
       "      <td>9.504025e-01</td>\n",
       "      <td>0.013605</td>\n",
       "      <td>0.074830</td>\n",
       "      <td>0.911565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.843376</td>\n",
       "      <td>0.058791</td>\n",
       "      <td>9.783307e-02</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.327586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.589330</td>\n",
       "      <td>0.085806</td>\n",
       "      <td>3.248640e-01</td>\n",
       "      <td>0.653061</td>\n",
       "      <td>0.088435</td>\n",
       "      <td>0.258503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.182135</td>\n",
       "      <td>8.177434e-01</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.506667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.109478</td>\n",
       "      <td>0.251413</td>\n",
       "      <td>6.391095e-01</td>\n",
       "      <td>0.051724</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.706897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.784247</td>\n",
       "      <td>0.189575</td>\n",
       "      <td>2.617842e-02</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.129252</td>\n",
       "      <td>0.054422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.125461</td>\n",
       "      <td>0.074802</td>\n",
       "      <td>7.997373e-01</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.430938</td>\n",
       "      <td>0.169276</td>\n",
       "      <td>3.997860e-01</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.533724</td>\n",
       "      <td>0.466271</td>\n",
       "      <td>5.380940e-06</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.013333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.646586</td>\n",
       "      <td>0.103632</td>\n",
       "      <td>2.497824e-01</td>\n",
       "      <td>0.706667</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.604040</td>\n",
       "      <td>0.046851</td>\n",
       "      <td>3.491098e-01</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.784247</td>\n",
       "      <td>0.189575</td>\n",
       "      <td>2.617842e-02</td>\n",
       "      <td>0.775862</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.051724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.183841</td>\n",
       "      <td>0.666898</td>\n",
       "      <td>1.492616e-01</td>\n",
       "      <td>0.197279</td>\n",
       "      <td>0.659864</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          y1        y2            y3       y_1       y_2       y_3\n",
       "0   0.011138  0.985176  3.685282e-03  0.027211  0.945578  0.027211\n",
       "1   0.590869  0.210588  1.985438e-01  0.650000  0.175000  0.175000\n",
       "2   0.843376  0.058791  9.783307e-02  0.520000  0.186667  0.293333\n",
       "3   0.902462  0.023093  7.444493e-02  0.911565  0.027211  0.061224\n",
       "4   0.567337  0.044450  3.882132e-01  0.480000  0.013333  0.506667\n",
       "5   0.432438  0.166710  4.008521e-01  0.531915  0.297872  0.170213\n",
       "6   0.013056  0.986944  1.614471e-08  0.765957  0.234043  0.000000\n",
       "7   0.000104  0.049494  9.504025e-01  0.013605  0.074830  0.911565\n",
       "8   0.843376  0.058791  9.783307e-02  0.500000  0.172414  0.327586\n",
       "9   0.589330  0.085806  3.248640e-01  0.653061  0.088435  0.258503\n",
       "10  0.000121  0.182135  8.177434e-01  0.013333  0.480000  0.506667\n",
       "11  0.109478  0.251413  6.391095e-01  0.051724  0.241379  0.706897\n",
       "12  0.784247  0.189575  2.617842e-02  0.816327  0.129252  0.054422\n",
       "13  0.125461  0.074802  7.997373e-01  0.125000  0.000000  0.875000\n",
       "14  0.430938  0.169276  3.997860e-01  0.440000  0.260000  0.300000\n",
       "15  0.533724  0.466271  5.380940e-06  0.826667  0.160000  0.013333\n",
       "16  0.646586  0.103632  2.497824e-01  0.706667  0.053333  0.240000\n",
       "17  0.604040  0.046851  3.491098e-01  0.650000  0.040000  0.310000\n",
       "18  0.784247  0.189575  2.617842e-02  0.775862  0.172414  0.051724\n",
       "19  0.183841  0.666898  1.492616e-01  0.197279  0.659864  0.142857"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "compare_y = y.eval(feed_dict={\n",
    "                    x_row: inputs_row_tests, \n",
    "                    x_col: inputs_col_tests, \n",
    "                    y_: target_row_tests, \n",
    "                    keep_prob: 1.0, \n",
    "                    keep_prob_col: 1.0})\n",
    "compare_y = compare_y.reshape(compare_y.shape[0], compare_y.shape[1])\n",
    "compare_y_ = y_.eval(feed_dict={\n",
    "                        x_row: inputs_row_tests,\n",
    "                        x_col: inputs_col_tests,\n",
    "                        y_: target_row_tests, \n",
    "                        keep_prob: 1.0,\n",
    "                        keep_prob_col: 1.0})\n",
    "compare_y_ = compare_y_.reshape(compare_y_.shape[0], compare_y_.shape[1])\n",
    "compare = pd.DataFrame(np.concatenate((compare_y, compare_y_), axis=1))\n",
    "compare.columns = [\"y1\",\"y2\",\"y3\",\"y_1\",\"y_2\",\"y_3\"]\n",
    "compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
