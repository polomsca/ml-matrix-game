{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# One-shot games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "- This is a compilation of results from several experiments where people play games like the [Prisoner's dilemma](https://en.wikipedia.org/wiki/Prisoner's_dilemma) or [Stag Hunt](https://en.wikipedia.org/wiki/Stag_hunt). See 'Games' for more information.\n",
    "\n",
    "- This is also an attempt to replicate and work on [machine learning](https://en.wikipedia.org/wiki/Machine_learning) models that attempt to predict how people make decisions in these games. See 'ML models' for more information.\n",
    "\n",
    "## Games\n",
    "\n",
    "To contribute to this [database](https://github.com/polomsca/one-shot-games/blob/master/gamesmxn.csv), you can submit any experiment with two-player, one-shot, normal-form games in this format:\n",
    "\n",
    "paper | game | matrixrow | matrixcol | choicerow | choicecol | shape | symmetric | n \n",
    "--- | --- | --- | --- | --- | --- | --- | --- | ---\n",
    "stahlwilson1994 | 1 | 40 10 70; 20 80 0; 30 100 60 | | 11 40; 0 40; 29 40 | | 3 3 | 1 | \n",
    "\n",
    "- **paper** : Paper authors and date published. Add 'et al' after the first author for papers with more than two authors. See 'Papers' for more information.\n",
    "- **game** : Game number if there are multiple games in one experiment. \n",
    "- **matrixrow** : Row player's payoff matrix. Separate elements with a space. Separate rows with a semicolon.\n",
    "- **matrixcol** : May be blank if player results are pooled.\n",
    "- **choicerow** : Row player's choice frequencies separated by semicolons. Fractions use a space instead of a slash. \n",
    "- **choicecol** : May be blank if player results are pooled.\n",
    "- **shape** : Number of rows followed by number of columns. Separate values by a space.\n",
    "- **symmetric** : '1' if symmetric, '0' otherwise.\n",
    "- **n** : Number of subjects if **choicerow** is expressed in decimals or if number of subjects is otherwise unclear.\n",
    "\n",
    "### Papers\n",
    "\n",
    "- Haruvy et al (2001) : Modeling and testing for heterogeneity in observed strategic behavior\n",
    "\n",
    "- Haruvy and Stahl (2007) : Equilibrium selection and bounded rationality in symmetric normal-form games\n",
    "\n",
    "- Rogers et al (2009) : Heterogeneous quantal response equilibrium and cognitive hierarchies\n",
    "\n",
    "- Stahl and Haruvy (2008) : Level-n bounded rationality and dominated strategies in normal-form games <sup>[1](#myfootnote1)</sup>\n",
    "\n",
    "- Stahl and Wilson (1994) : Experimental evidence on players' models of other players\n",
    "\n",
    "- Stahl and Wilson (1995) : On players' models of other players, theory and experimental evidence\n",
    "\n",
    "- Goeree and Holt (2001) : Ten little treasures of game theory and ten intuitive contradictions \n",
    "    - (only games from \"A Matching Pennies Game\" and \"The Kreps Game\")\n",
    "\n",
    "- Rydval and Ortmann (2005) : Loss avoidance as selection principle, evidence from simple stag-hunt games\n",
    "\n",
    "- Haruvy and Stahl (1998) : An empirical model of equilibrium selection in symmetric normal-form games\n",
    "\n",
    "- Costa-Gomes et al (1998) : Cognition and behavior in normal-form games, an experimental study \n",
    "    - (does not include TS treatment)\n",
    "\n",
    "### Footnotes\n",
    "\n",
    "[<a name=\"myfootnote1\">1</a>] Appendix D, Game 10 is printed incorrectly as\n",
    "\n",
    "12 | 63 | 22 \n",
    "--- | --- | ---\n",
    "0 | 0 | 38 \n",
    "55 | 25 | 40 \n",
    "35 | 35 | 43 \n",
    "\n",
    "Game 10 should be read instead as\n",
    "\n",
    "0 | 12 | 63 \n",
    "--- | --- | ---\n",
    "25 | 0 | 0\n",
    "0 | 55 | 25 \n",
    "100 | 35 | 35 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML models\n",
    "The following is my attempt to replicate results from: \n",
    "\n",
    "- Hartford et al (2016) : Deep learning for predicting human strategic behavior\n",
    "    - 'Gamenet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string as string\n",
    "from __future__ import division\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import_csv = pd.read_csv('gamesmxn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Combine same games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for i in range(1, import_csv.shape[0]):\n",
    "    if pd.DataFrame(import_csv['matrixrow'][0:i] == import_csv['matrixrow'][i]).values.any():\n",
    "        repeatmat = import_csv['matrixrow'][0:i][import_csv['matrixrow'][0:i] == import_csv['matrixrow'][i]].index[0]\n",
    "        choicesum = np.matrix(import_csv['choicerow'][repeatmat]) + np.matrix(import_csv['choicerow'][i])\n",
    "        choicesum = string.replace(str(choicesum),'[','')\n",
    "        choicesum = string.replace(str(choicesum),']]','')\n",
    "        choicesum = string.replace(str(choicesum),']\\n',';')\n",
    "        import_csv.set_value(repeatmat, 'choicerow', choicesum)\n",
    "        import_csv.drop([i], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Select games to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tmp = np.empty((import_csv.shape[0]))\n",
    "tmp[:] = np.NAN\n",
    "for i in range(import_csv.shape[0]):\n",
    "    if (import_csv['shape'][i] == '3 3' \n",
    "        and import_csv['symmetric'][i] == 1 \n",
    "        and import_csv['paper'][i] != 'stahlwilson1995'):\n",
    "        tmp[i] = i\n",
    "index = tmp[~np.isnan(tmp)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "inputs_row = np.zeros((index.shape[0], 3, 3, 2))\n",
    "inputs_col = np.zeros((index.shape[0], 3, 3, 2))\n",
    "target_row = np.zeros((index.shape[0], 3, 1))\n",
    "for j in range(index.shape[0]):\n",
    "    Ur = np.matrix(import_csv['matrixrow'][int(index[j])])\n",
    "    Ur = (Ur-np.mean(Ur))/np.std(Ur)\n",
    "    Uc = np.transpose(Ur)\n",
    "    ar = np.matrix(import_csv['choicerow'][int(index[j])])\n",
    "    if ar.shape[1] == 2:\n",
    "        ar = ar[:,0]/ar[:,1]\n",
    "    inputs_row[j, :, :, 0] = Ur\n",
    "    inputs_row[j, :, :, 1] = Uc\n",
    "    inputs_col[j, :, :, 0] = Uc\n",
    "    inputs_col[j, :, :, 1] = Ur\n",
    "    target_row[j] = ar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Training and test sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "shuffle = np.random.permutation(range(inputs_row.shape[0]))\n",
    "index_train = shuffle[0:inputs_row.shape[0]//5*4] \n",
    "index_tests = shuffle[inputs_row.shape[0]//5*4:inputs_row.shape[0]]\n",
    "inputs_row_train = inputs_row[index_train]\n",
    "inputs_col_train = inputs_col[index_train]\n",
    "target_row_train = target_row[index_train]\n",
    "inputs_row_tests = inputs_row[index_tests]\n",
    "inputs_col_tests = inputs_col[index_tests]\n",
    "target_row_tests = target_row[index_tests]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Weights and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Convolution and pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def rw_pool(x,c):\n",
    "    x_max = tf.reduce_max(x, axis=2)\n",
    "    x_til = tf.tile(x_max,[1,3,1])\n",
    "    x_sha = tf.reshape(x_til,[-1,3,3,c])\n",
    "    return tf.transpose(x_sha, perm=[0,2,1,3])\n",
    "\n",
    "def cw_pool(x,c):\n",
    "    x_max = tf.reduce_max(x, axis=1)\n",
    "    x_til = tf.tile(x_max,[1,3,1])\n",
    "    return tf.reshape(x_til,[-1,3,3,c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Input and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x_row = tf.placeholder(tf.float32, shape=[None, 3, 3, 2])\n",
    "x_col = tf.placeholder(tf.float32, shape=[None, 3, 3, 2])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 3, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Hidden layer 1 (row player)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Tensorflow version `0.12.1` uses `tf.concat(axis, values, name='concat')`, not `tf.concat(values, axis, name='concat')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x_pool1 = tf.concat([x_row, rw_pool(x_row, 2), cw_pool(x_row, 2)], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "W_conv1 = weight_variable([1, 1, 6, 50])\n",
    "b_conv1 = bias_variable([50])\n",
    "h_conv1 = tf.nn.relu(conv2d(x_pool1, W_conv1) + b_conv1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Hidden layer 2 (row player)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow version `0.12.1` uses `tf.concat(axis, values, name='concat')`, not `tf.concat(values, axis, name='concat')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x_pool2 = tf.concat([h_conv1, rw_pool(h_conv1, 50), cw_pool(h_conv1, 50)], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "W_conv2 = weight_variable([1, 1, 150, 50])\n",
    "b_conv2 = bias_variable([50])\n",
    "h_conv2 = tf.nn.relu(conv2d(x_pool2, W_conv2) + b_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_conv2_drop = tf.nn.dropout(h_conv2, keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<div style=\"text-align: right\"> <h3> Hidden layer 1 (col player) </h3> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow version `0.12.1` uses `tf.concat(axis, values, name='concat')`, not `tf.concat(values, axis, name='concat')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x_pool1_col = tf.concat([x_col, rw_pool(x_col, 2), cw_pool(x_col, 2)], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "W_conv1_col = weight_variable([1, 1, 6, 50])\n",
    "b_conv1_col = bias_variable([50])\n",
    "h_conv1_col = tf.nn.relu(conv2d(x_pool1_col, W_conv1_col) + b_conv1_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<div style=\"text-align: right\"> <h3> Hidden layer 2 (col player) </h3> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x_pool2_col = tf.concat([h_conv1_col, rw_pool(h_conv1_col, 50), cw_pool(h_conv1_col, 50)], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "W_conv2_col = weight_variable([1, 1, 150, 50])\n",
    "b_conv2_col = bias_variable([50])\n",
    "h_conv2_col = tf.nn.relu(conv2d(x_pool2_col, W_conv2_col) + b_conv2_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "keep_prob_col = tf.placeholder(tf.float32)\n",
    "h_conv2_col_drop = tf.nn.dropout(h_conv2_col, keep_prob_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<div style=\"text-align: right\"> <h3> Action response layer 0 (col player) </h3> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "W_rwsm0 = weight_variable([1, 1, 50, 50])\n",
    "h_rdsm1 = conv2d(h_conv2_col_drop, W_rwsm0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ar_rwsm0_col = tf.reduce_sum(h_conv2_col_drop, axis=2)\n",
    "ar_sfmx0_col = tf.nn.softmax(ar_rwsm0_col, dim=1)\n",
    "ar_sfmx0_col = tf.slice(ar_sfmx0_col, [0, 0, 0], [-1, 3, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Action response layer 1 (row player response to col player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "W_rdsm1 = weight_variable([1, 1, 50, 50])\n",
    "h_rdsm1 = conv2d(h_conv2_drop, W_rdsm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ar_rdsm1 = tf.reduce_sum(h_rdsm1, axis=3)\n",
    "ar_dtpt1 = tf.matmul(ar_rdsm1, ar_sfmx0_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y = tf.nn.softmax(ar_dtpt1, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "beta = 0.01\n",
    "regularizer = (tf.nn.l2_loss(W_conv1) \n",
    "               + tf.nn.l2_loss(W_conv2) \n",
    "               + tf.nn.l2_loss(W_conv1_col) \n",
    "               + tf.nn.l2_loss(W_conv2_col)\n",
    "               + tf.nn.l2_loss(W_rwsm0) \n",
    "               + tf.nn.l2_loss(W_rdsm1))\n",
    "#cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y) + beta * regularizer, reduction_indices=[1]))\n",
    "cross_entropy = -tf.reduce_mean(tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.AdamOptimizer(0.0002,0.9,0.999,1e-8).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, train accuracy 0, train NLL 1.19007\n",
      "step 100, train accuracy 0.8, train NLL 0.731989\n",
      "step 200, train accuracy 1, train NLL 0.71316\n",
      "step 300, train accuracy 0.866667, train NLL 0.832534\n",
      "step 400, train accuracy 0.866667, train NLL 0.795097\n",
      "step 500, train accuracy 0.933333, train NLL 0.806196\n",
      "step 600, train accuracy 1, train NLL 0.752479\n",
      "step 700, train accuracy 0.933333, train NLL 0.778576\n",
      "step 800, train accuracy 1, train NLL 0.755481\n",
      "step 900, train accuracy 1, train NLL 0.750553\n",
      "step 1000, train accuracy 0.933333, train NLL 0.734352\n",
      "step 1100, train accuracy 1, train NLL 0.820847\n",
      "step 1200, train accuracy 0.933333, train NLL 0.733628\n",
      "step 1300, train accuracy 1, train NLL 0.754738\n",
      "step 1400, train accuracy 1, train NLL 0.670996\n",
      "step 1500, train accuracy 0.933333, train NLL 0.684518\n",
      "step 1600, train accuracy 0.933333, train NLL 0.788794\n",
      "step 1700, train accuracy 1, train NLL 0.681856\n",
      "step 1800, train accuracy 1, train NLL 0.73045\n",
      "step 1900, train accuracy 1, train NLL 0.75478\n",
      "step 2000, train accuracy 1, train NLL 0.676086\n",
      "step 2100, train accuracy 1, train NLL 0.716636\n",
      "step 2200, train accuracy 1, train NLL 0.601086\n",
      "step 2300, train accuracy 0.933333, train NLL 0.763585\n",
      "step 2400, train accuracy 0.933333, train NLL 0.630244\n",
      "step 2500, train accuracy 1, train NLL 0.764764\n",
      "step 2600, train accuracy 1, train NLL 0.783351\n",
      "step 2700, train accuracy 1, train NLL 0.788758\n",
      "step 2800, train accuracy 0.866667, train NLL 0.668402\n",
      "step 2900, train accuracy 1, train NLL 0.764844\n",
      "step 3000, train accuracy 1, train NLL 0.702725\n",
      "step 3100, train accuracy 0.933333, train NLL 0.724997\n",
      "step 3200, train accuracy 1, train NLL 0.631525\n",
      "step 3300, train accuracy 1, train NLL 0.797556\n",
      "step 3400, train accuracy 1, train NLL 0.738909\n",
      "step 3500, train accuracy 1, train NLL 0.56894\n",
      "step 3600, train accuracy 1, train NLL 0.698714\n",
      "step 3700, train accuracy 0.933333, train NLL 0.6876\n",
      "step 3800, train accuracy 0.933333, train NLL 0.800445\n",
      "step 3900, train accuracy 1, train NLL 0.736892\n",
      "step 4000, train accuracy 1, train NLL 0.703098\n",
      "step 4100, train accuracy 0.933333, train NLL 0.766593\n",
      "step 4200, train accuracy 1, train NLL 0.741256\n",
      "step 4300, train accuracy 1, train NLL 0.712206\n",
      "step 4400, train accuracy 1, train NLL 0.629777\n",
      "step 4500, train accuracy 1, train NLL 0.663247\n",
      "step 4600, train accuracy 1, train NLL 0.734027\n",
      "step 4700, train accuracy 1, train NLL 0.734354\n",
      "step 4800, train accuracy 1, train NLL 0.762419\n",
      "step 4900, train accuracy 1, train NLL 0.762579\n"
     ]
    }
   ],
   "source": [
    "for i in range(5000):\n",
    "    if i%5 == 0:\n",
    "        shuffle = np.random.permutation(range(inputs_row_train.shape[0]))\n",
    "    inputs_row_train_batch = inputs_row_train[shuffle[shuffle.shape[0]//5*(i%5):shuffle.shape[0]//5*(i%5+1)]]\n",
    "    inputs_col_train_batch = inputs_col_train[shuffle[shuffle.shape[0]//5*(i%5):shuffle.shape[0]//5*(i%5+1)]]\n",
    "    target_row_train_batch = target_row_train[shuffle[shuffle.shape[0]//5*(i%5):shuffle.shape[0]//5*(i%5+1)]]\n",
    "    if i%100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={\n",
    "                x_row: inputs_row_train_batch,\n",
    "                x_col: inputs_col_train_batch,\n",
    "                y_: target_row_train_batch, \n",
    "                keep_prob: 1.0,\n",
    "                keep_prob_col: 1.0})\n",
    "        train_NLL = cross_entropy.eval(feed_dict={\n",
    "                x_row: inputs_row_train_batch, \n",
    "                x_col: inputs_col_train_batch,\n",
    "                y_: target_row_train_batch,\n",
    "                keep_prob: 1.0,\n",
    "                keep_prob_col: 1.0})\n",
    "        print(\"step %d, train accuracy %g, train NLL %g\"%(i, train_accuracy, train_NLL))\n",
    "    train_step.run(feed_dict={x_row: inputs_row_train_batch, \n",
    "                              x_col: inputs_col_train_batch, \n",
    "                              y_: target_row_train_batch, \n",
    "                              keep_prob: 0.8,\n",
    "                              keep_prob_col: 0.8})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 1, test NLL 0.740187\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = accuracy.eval(feed_dict={\n",
    "        x_row: inputs_row_tests,\n",
    "        x_col: inputs_col_tests,\n",
    "        y_: target_row_tests, \n",
    "        keep_prob: 1.0,\n",
    "        keep_prob_col: 1.0})\n",
    "test_NLL = cross_entropy.eval(feed_dict={\n",
    "        x_row: inputs_row_tests,\n",
    "        x_col: inputs_col_tests,\n",
    "        y_: target_row_tests, \n",
    "        keep_prob: 1.0,\n",
    "        keep_prob_col: 1.0})\n",
    "print(\"test accuracy %g, test NLL %g\"%(test_accuracy, test_NLL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>y3</th>\n",
       "      <th>y_1</th>\n",
       "      <th>y_2</th>\n",
       "      <th>y_3</th>\n",
       "      <th>RMSE 1</th>\n",
       "      <th>RMSE 2</th>\n",
       "      <th>RMSE 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.343860</td>\n",
       "      <td>0.626594</td>\n",
       "      <td>0.029545</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006140</td>\n",
       "      <td>0.023406</td>\n",
       "      <td>0.029545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.288495</td>\n",
       "      <td>0.018925</td>\n",
       "      <td>0.692580</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>0.048495</td>\n",
       "      <td>0.151075</td>\n",
       "      <td>0.102580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.509489</td>\n",
       "      <td>0.213682</td>\n",
       "      <td>0.276829</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.069489</td>\n",
       "      <td>0.046318</td>\n",
       "      <td>0.023171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.039103</td>\n",
       "      <td>0.948503</td>\n",
       "      <td>0.012394</td>\n",
       "      <td>0.027211</td>\n",
       "      <td>0.945578</td>\n",
       "      <td>0.027211</td>\n",
       "      <td>0.011892</td>\n",
       "      <td>0.002925</td>\n",
       "      <td>0.014817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.035590</td>\n",
       "      <td>0.047360</td>\n",
       "      <td>0.917050</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.931973</td>\n",
       "      <td>0.015181</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.014922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.005410</td>\n",
       "      <td>0.071876</td>\n",
       "      <td>0.922714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.005410</td>\n",
       "      <td>0.088124</td>\n",
       "      <td>0.082714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.673894</td>\n",
       "      <td>0.079664</td>\n",
       "      <td>0.246441</td>\n",
       "      <td>0.693878</td>\n",
       "      <td>0.102041</td>\n",
       "      <td>0.204082</td>\n",
       "      <td>0.019983</td>\n",
       "      <td>0.022376</td>\n",
       "      <td>0.042360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.805431</td>\n",
       "      <td>0.058349</td>\n",
       "      <td>0.136220</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.212766</td>\n",
       "      <td>0.039473</td>\n",
       "      <td>0.037073</td>\n",
       "      <td>0.076546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.922429</td>\n",
       "      <td>0.008202</td>\n",
       "      <td>0.069369</td>\n",
       "      <td>0.829787</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.148936</td>\n",
       "      <td>0.092642</td>\n",
       "      <td>0.013074</td>\n",
       "      <td>0.079568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.611113</td>\n",
       "      <td>0.360435</td>\n",
       "      <td>0.028452</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.312925</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.055553</td>\n",
       "      <td>0.047510</td>\n",
       "      <td>0.008044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.418995</td>\n",
       "      <td>0.111751</td>\n",
       "      <td>0.469253</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>0.088995</td>\n",
       "      <td>0.128249</td>\n",
       "      <td>0.039253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.184111</td>\n",
       "      <td>0.742311</td>\n",
       "      <td>0.073578</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.802721</td>\n",
       "      <td>0.054422</td>\n",
       "      <td>0.041254</td>\n",
       "      <td>0.060410</td>\n",
       "      <td>0.019156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.126088</td>\n",
       "      <td>0.173311</td>\n",
       "      <td>0.700601</td>\n",
       "      <td>0.051724</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.706897</td>\n",
       "      <td>0.074364</td>\n",
       "      <td>0.068069</td>\n",
       "      <td>0.006296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.620560</td>\n",
       "      <td>0.054131</td>\n",
       "      <td>0.325308</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.029440</td>\n",
       "      <td>0.054131</td>\n",
       "      <td>0.024692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.686481</td>\n",
       "      <td>0.218090</td>\n",
       "      <td>0.095430</td>\n",
       "      <td>0.787234</td>\n",
       "      <td>0.148936</td>\n",
       "      <td>0.063830</td>\n",
       "      <td>0.100754</td>\n",
       "      <td>0.069154</td>\n",
       "      <td>0.031600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.274682</td>\n",
       "      <td>0.520005</td>\n",
       "      <td>0.205313</td>\n",
       "      <td>0.191489</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.191489</td>\n",
       "      <td>0.083192</td>\n",
       "      <td>0.097016</td>\n",
       "      <td>0.013823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.288998</td>\n",
       "      <td>0.018757</td>\n",
       "      <td>0.692246</td>\n",
       "      <td>0.293103</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.672414</td>\n",
       "      <td>0.004106</td>\n",
       "      <td>0.015726</td>\n",
       "      <td>0.019832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.324693</td>\n",
       "      <td>0.646728</td>\n",
       "      <td>0.028579</td>\n",
       "      <td>0.425532</td>\n",
       "      <td>0.531915</td>\n",
       "      <td>0.042553</td>\n",
       "      <td>0.100839</td>\n",
       "      <td>0.114813</td>\n",
       "      <td>0.013974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.503447</td>\n",
       "      <td>0.187789</td>\n",
       "      <td>0.308764</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.327586</td>\n",
       "      <td>0.003447</td>\n",
       "      <td>0.015375</td>\n",
       "      <td>0.018823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.922429</td>\n",
       "      <td>0.008202</td>\n",
       "      <td>0.069369</td>\n",
       "      <td>0.843537</td>\n",
       "      <td>0.034014</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>0.078892</td>\n",
       "      <td>0.025811</td>\n",
       "      <td>0.053080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          y1        y2        y3       y_1       y_2       y_3    RMSE 1  \\\n",
       "0   0.343860  0.626594  0.029545  0.350000  0.650000  0.000000  0.006140   \n",
       "1   0.288495  0.018925  0.692580  0.240000  0.170000  0.590000  0.048495   \n",
       "2   0.509489  0.213682  0.276829  0.440000  0.260000  0.300000  0.069489   \n",
       "3   0.039103  0.948503  0.012394  0.027211  0.945578  0.027211  0.011892   \n",
       "4   0.035590  0.047360  0.917050  0.020408  0.047619  0.931973  0.015181   \n",
       "5   0.005410  0.071876  0.922714  0.000000  0.160000  0.840000  0.005410   \n",
       "6   0.673894  0.079664  0.246441  0.693878  0.102041  0.204082  0.019983   \n",
       "7   0.805431  0.058349  0.136220  0.765957  0.021277  0.212766  0.039473   \n",
       "8   0.922429  0.008202  0.069369  0.829787  0.021277  0.148936  0.092642   \n",
       "9   0.611113  0.360435  0.028452  0.666667  0.312925  0.020408  0.055553   \n",
       "10  0.418995  0.111751  0.469253  0.330000  0.240000  0.430000  0.088995   \n",
       "11  0.184111  0.742311  0.073578  0.142857  0.802721  0.054422  0.041254   \n",
       "12  0.126088  0.173311  0.700601  0.051724  0.241379  0.706897  0.074364   \n",
       "13  0.620560  0.054131  0.325308  0.650000  0.000000  0.350000  0.029440   \n",
       "14  0.686481  0.218090  0.095430  0.787234  0.148936  0.063830  0.100754   \n",
       "15  0.274682  0.520005  0.205313  0.191489  0.617021  0.191489  0.083192   \n",
       "16  0.288998  0.018757  0.692246  0.293103  0.034483  0.672414  0.004106   \n",
       "17  0.324693  0.646728  0.028579  0.425532  0.531915  0.042553  0.100839   \n",
       "18  0.503447  0.187789  0.308764  0.500000  0.172414  0.327586  0.003447   \n",
       "19  0.922429  0.008202  0.069369  0.843537  0.034014  0.122449  0.078892   \n",
       "\n",
       "      RMSE 2    RMSE 3  \n",
       "0   0.023406  0.029545  \n",
       "1   0.151075  0.102580  \n",
       "2   0.046318  0.023171  \n",
       "3   0.002925  0.014817  \n",
       "4   0.000259  0.014922  \n",
       "5   0.088124  0.082714  \n",
       "6   0.022376  0.042360  \n",
       "7   0.037073  0.076546  \n",
       "8   0.013074  0.079568  \n",
       "9   0.047510  0.008044  \n",
       "10  0.128249  0.039253  \n",
       "11  0.060410  0.019156  \n",
       "12  0.068069  0.006296  \n",
       "13  0.054131  0.024692  \n",
       "14  0.069154  0.031600  \n",
       "15  0.097016  0.013823  \n",
       "16  0.015726  0.019832  \n",
       "17  0.114813  0.013974  \n",
       "18  0.015375  0.018823  \n",
       "19  0.025811  0.053080  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "compare_y = y.eval(feed_dict={\n",
    "                    x_row: inputs_row_tests, \n",
    "                    x_col: inputs_col_tests, \n",
    "                    y_: target_row_tests, \n",
    "                    keep_prob: 1.0, \n",
    "                    keep_prob_col: 1.0})\n",
    "compare_y = compare_y.reshape(compare_y.shape[0], compare_y.shape[1])\n",
    "compare_y_ = y_.eval(feed_dict={\n",
    "                        x_row: inputs_row_tests,\n",
    "                        x_col: inputs_col_tests,\n",
    "                        y_: target_row_tests, \n",
    "                        keep_prob: 1.0,\n",
    "                        keep_prob_col: 1.0})\n",
    "compare_y_ = compare_y_.reshape(compare_y_.shape[0], compare_y_.shape[1])\n",
    "compare = pd.DataFrame(np.concatenate((compare_y, compare_y_), axis=1))\n",
    "compare.columns = [\"y1\",\"y2\",\"y3\",\"y_1\",\"y_2\",\"y_3\"]\n",
    "compare['RMSE 1'] = np.sqrt((compare['y1'] - compare['y_1'])**2)\n",
    "compare['RMSE 2'] = np.sqrt((compare['y2'] - compare['y_2'])**2)\n",
    "compare['RMSE 3'] = np.sqrt((compare['y3'] - compare['y_3'])**2)\n",
    "compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
