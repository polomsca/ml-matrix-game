{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# One-shot games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Overview\n",
    "\n",
    "- This is a database of laboratory experiments that study how people play games like the [Prisoner's dilemma](https://en.wikipedia.org/wiki/Prisoner's_dilemma), [Chicken](http://economics.wikia.com/wiki/Chicken_game), and [Stag Hunt](https://en.wikipedia.org/wiki/Stag_hunt). We hope studying games from many experiments can help us understand how people make decisions during games and how they learn to play over time. See [Games](#games) for more information on the database itself, how to use it, and how to contribute.\n",
    "\n",
    "- This is also an attempt to replicate and work on [machine learning](https://en.wikipedia.org/wiki/Machine_learning) (ML) models that predict how people make decisions during games. We hope developing ML models from the many experiments in our database can help us understand how to best model the types of strategies people develop when playing games. See [ML models](#mlmodels) for more information on models, how to use them, and how to contribute.\n",
    "\n",
    "## Games <a name=\"games\"/>\n",
    "\n",
    "You may contribute to this [database](https://github.com/polomsca/one-shot-games/blob/master/gamesmxn.csv), by submitting any experiment with two-player, one-shot, normal-form games in this format:\n",
    "\n",
    "paper | game | matrixrow | matrixcol | choicerow | choicecol | shape | symmetric | n \n",
    "--- | --- | --- | --- | --- | --- | --- | --- | ---\n",
    "stahlwilson1994 | 1 | 40 10 70; 20 80 0; 30 100 60 | | 11 40; 0 40; 29 40 | | 3 3 | 1 | \n",
    "\n",
    "- **paper** : Paper authors and date published. Add 'et al' after the first author for papers with more than two authors. See [Papers](#papers) for more information.\n",
    "- **game** : Game number if there are multiple games in one experiment. \n",
    "- **matrixrow** : Row player's payoff matrix. Separate elements with a space. Separate rows with a semicolon.\n",
    "- **matrixcol** : May be blank if player results are pooled.\n",
    "- **choicerow** : Row player's choice frequencies separated by semicolons. Fractions use a space instead of a slash. \n",
    "- **choicecol** : May be blank if player results are pooled.\n",
    "- **shape** : Number of rows followed by number of columns. Separate values by a space.\n",
    "- **symmetric** : '1' if symmetric, '0' otherwise.\n",
    "- **n** : Number of subjects if **choicerow** is expressed in decimals or if number of subjects is otherwise unclear.\n",
    "\n",
    "### Papers <a name=\"papers\"/>\n",
    "\n",
    "- Haruvy et al (2001) : Modeling and testing for heterogeneity in observed strategic behavior\n",
    "\n",
    "- Haruvy and Stahl (2007) : Equilibrium selection and bounded rationality in symmetric normal-form games\n",
    "\n",
    "- Rogers et al (2009) : Heterogeneous quantal response equilibrium and cognitive hierarchies\n",
    "\n",
    "- Stahl and Haruvy (2008) : Level-n bounded rationality and dominated strategies in normal-form games <sup>[1](#myfootnote1)</sup>\n",
    "\n",
    "- Stahl and Wilson (1994) : Experimental evidence on players' models of other players\n",
    "\n",
    "- Stahl and Wilson (1995) : On players' models of other players, theory and experimental evidence\n",
    "\n",
    "- Goeree and Holt (2001) : Ten little treasures of game theory and ten intuitive contradictions \n",
    "    - (only games from \"A Matching Pennies Game\" and \"The Kreps Game\")\n",
    "\n",
    "- Rydval and Ortmann (2005) : Loss avoidance as selection principle, evidence from simple stag-hunt games\n",
    "\n",
    "- Haruvy and Stahl (1998) : An empirical model of equilibrium selection in symmetric normal-form games\n",
    "\n",
    "- Costa-Gomes et al (1998) : Cognition and behavior in normal-form games, an experimental study \n",
    "    - (does not include TS treatment)\n",
    "\n",
    "#### Footnotes\n",
    "\n",
    "[<a name=\"myfootnote1\">1</a>] Appendix D, Game 10 is printed incorrectly as\n",
    "\n",
    "12 | 63 | 22 \n",
    "--- | --- | ---\n",
    "0 | 0 | 38 \n",
    "55 | 25 | 40 \n",
    "35 | 35 | 43 \n",
    "\n",
    "Game 10 should be read instead as\n",
    "\n",
    "0 | 12 | 63 \n",
    "--- | --- | ---\n",
    "25 | 0 | 0\n",
    "0 | 55 | 25 \n",
    "100 | 35 | 35 \n",
    "\n",
    "## ML models <a name=\"mlmodels\"/>\n",
    "\n",
    "The following program is my attempt to replicate results from: \n",
    "\n",
    "- Hartford et al (2016) : Deep learning for predicting human strategic behavior ('GameNet' model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string as string\n",
    "from __future__ import division\n",
    "import time\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import_csv = pd.read_csv('gamesmxn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Combine same games\n",
    "Currently not enough games to afford this.\n",
    "Also does not appear to work in Python 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "```python\n",
    "for i in range(1, import_csv.shape[0]):\n",
    "    if pd.DataFrame(import_csv['matrixrow'][0:i] == import_csv['matrixrow'][i]).values.any():\n",
    "        repeatmat = import_csv['matrixrow'][0:i][import_csv['matrixrow'][0:i] == import_csv['matrixrow'][i]].index[0]\n",
    "        choicesum = np.matrix(import_csv['choicerow'][repeatmat]) + np.matrix(import_csv['choicerow'][i])\n",
    "        choicesum = string.replace(str(choicesum),'[','')\n",
    "        choicesum = string.replace(str(choicesum),']]','')\n",
    "        choicesum = string.replace(str(choicesum),']\\n',';')\n",
    "        import_csv.set_value(repeatmat, 'choicerow', choicesum)\n",
    "        import_csv.drop([i], inplace=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Select games to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently we are only using games of size 3x3. We remove 'stahlwilson1995' due to current uncertainty about some of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tmp = np.empty((import_csv.shape[0]))\n",
    "tmp[:] = np.NAN\n",
    "for i in range(import_csv.shape[0]):\n",
    "    if (import_csv['shape'][i] == '3 3' \n",
    "        and import_csv['symmetric'][i]\n",
    "        and import_csv['paper'][i] != 'stahlwilson1995') == 1:\n",
    "        tmp[i] = i\n",
    "index = tmp[~np.isnan(tmp)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "inputs_row = np.zeros((index.shape[0], 3, 3, 2))\n",
    "inputs_col = np.zeros((index.shape[0], 3, 3, 2))\n",
    "target_row = np.zeros((index.shape[0], 3, 1))\n",
    "for j in range(index.shape[0]):\n",
    "    Ur = np.matrix(import_csv['matrixrow'][int(index[j])])\n",
    "    Ur = (Ur-np.mean(Ur))/np.std(Ur)\n",
    "    Uc = np.transpose(Ur)\n",
    "    ar = np.matrix(import_csv['choicerow'][int(index[j])])\n",
    "    if ar.shape[1] == 2:\n",
    "        ar = ar[:,0]/ar[:,1]\n",
    "    inputs_row[j, :, :, 0] = Ur\n",
    "    inputs_row[j, :, :, 1] = Uc\n",
    "    inputs_col[j, :, :, 0] = Uc\n",
    "    inputs_col[j, :, :, 1] = Ur\n",
    "    target_row[j] = ar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Weights and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Convolution and pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def rw_pool(x,c):\n",
    "    x_max = tf.reduce_max(x, axis=2)\n",
    "    x_til = tf.tile(x_max,[1,3,1])\n",
    "    x_sha = tf.reshape(x_til,[-1,3,3,c])\n",
    "    return tf.transpose(x_sha, perm=[0,2,1,3])\n",
    "\n",
    "def cw_pool(x,c):\n",
    "    x_max = tf.reduce_max(x, axis=1)\n",
    "    x_til = tf.tile(x_max,[1,3,1])\n",
    "    return tf.reshape(x_til,[-1,3,3,c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Input and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x_row = tf.placeholder(tf.float32, shape=[None, 3, 3, 2])\n",
    "x_col = tf.placeholder(tf.float32, shape=[None, 3, 3, 2])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 3, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Hidden layer 1 (row player)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Tensorflow version `0.12.1` uses `tf.concat(axis, values, name='concat')`, not `tf.concat(values, axis, name='concat')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x_pool1 = tf.concat([x_row, rw_pool(x_row, 2), cw_pool(x_row, 2)], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "W_conv1 = weight_variable([1, 1, 6, 50])\n",
    "b_conv1 = bias_variable([50])\n",
    "h_conv1 = tf.nn.relu(conv2d(x_pool1, W_conv1) + b_conv1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Hidden layer 2 (row player)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Tensorflow version `0.12.1` uses `tf.concat(axis, values, name='concat')`, not `tf.concat(values, axis, name='concat')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x_pool2 = tf.concat([h_conv1, rw_pool(h_conv1, 50), cw_pool(h_conv1, 50)], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "W_conv2 = weight_variable([1, 1, 150, 50])\n",
    "b_conv2 = bias_variable([50])\n",
    "h_conv2 = tf.nn.relu(conv2d(x_pool2, W_conv2) + b_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_conv2_drop = tf.nn.dropout(h_conv2, keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<div style=\"text-align: right\"> <h3> Hidden layer 1 (col player) </h3> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Tensorflow version `0.12.1` uses `tf.concat(axis, values, name='concat')`, not `tf.concat(values, axis, name='concat')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x_pool1_col = tf.concat([x_col, rw_pool(x_col, 2), cw_pool(x_col, 2)], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "W_conv1_col = weight_variable([1, 1, 6, 50])\n",
    "b_conv1_col = bias_variable([50])\n",
    "h_conv1_col = tf.nn.relu(conv2d(x_pool1_col, W_conv1_col) + b_conv1_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<div style=\"text-align: right\"> <h3> Hidden layer 2 (col player) </h3> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x_pool2_col = tf.concat([h_conv1_col, rw_pool(h_conv1_col, 50), cw_pool(h_conv1_col, 50)], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "W_conv2_col = weight_variable([1, 1, 150, 50])\n",
    "b_conv2_col = bias_variable([50])\n",
    "h_conv2_col = tf.nn.relu(conv2d(x_pool2_col, W_conv2_col) + b_conv2_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "keep_prob_col = tf.placeholder(tf.float32)\n",
    "h_conv2_col_drop = tf.nn.dropout(h_conv2_col, keep_prob_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<div style=\"text-align: right\"> <h3> Action response layer 0 (col player) </h3> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "W_rwsm0 = weight_variable([1, 1, 50, 50])\n",
    "h_rdsm1 = conv2d(h_conv2_col_drop, W_rwsm0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ar_rwsm0_col = tf.reduce_sum(h_conv2_col_drop, axis=2)\n",
    "ar_sfmx0_col = tf.nn.softmax(ar_rwsm0_col, dim=1)\n",
    "ar_sfmx0_col = tf.slice(ar_sfmx0_col, [0, 0, 0], [-1, 3, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Action response layer 1 (row player response to col player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "W_rdsm1 = weight_variable([1, 1, 50, 50])\n",
    "h_rdsm1 = conv2d(h_conv2_drop, W_rdsm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ar_rdsm1 = tf.reduce_sum(h_rdsm1, axis=3)\n",
    "ar_dtpt1 = tf.matmul(ar_rdsm1, ar_sfmx0_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y = tf.nn.softmax(ar_dtpt1, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "beta = 0.01\n",
    "regularizer = (tf.nn.l2_loss(W_conv1) \n",
    "               + tf.nn.l2_loss(W_conv2) \n",
    "               + tf.nn.l2_loss(W_conv1_col) \n",
    "               + tf.nn.l2_loss(W_conv2_col)\n",
    "               + tf.nn.l2_loss(W_rwsm0) \n",
    "               + tf.nn.l2_loss(W_rdsm1))\n",
    "#cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y)+beta*regularizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.AdamOptimizer(0.0002,0.9,0.999,1e-8).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Training and testing with 10 times 10-fold cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate KL divergence in scipy due to uncertainty in the KL divergence calculation in Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, train accuracy 0.352941, train NLL 0.805027\n",
      "step 1500, train accuracy 0.941176, train NLL 0.0242934\n",
      "test accuracy 0.888889, test NLL 0.0242812\n",
      "RMSE 0.269147\n",
      "KL 0.399837\n",
      "step 0, train accuracy 0.176471, train NLL 0.787561\n",
      "step 1500, train accuracy 0.941176, train NLL 0.0208457\n",
      "test accuracy 0.666667, test NLL 0.0208374\n",
      "RMSE 0.319826\n",
      "KL 0.692673\n",
      "step 0, train accuracy 0.411765, train NLL 0.796069\n",
      "step 1500, train accuracy 0.941176, train NLL 0.0219251\n",
      "test accuracy 0.777778, test NLL 0.0219114\n",
      "RMSE 0.260479\n",
      "KL 0.431069\n",
      "step 0, train accuracy 0.588235, train NLL 0.802569\n",
      "step 1500, train accuracy 0.882353, train NLL 0.0222138\n",
      "test accuracy 0.888889, test NLL 0.0221944\n",
      "RMSE 0.239906\n",
      "KL 0.400493\n",
      "step 0, train accuracy 0.647059, train NLL 0.795531\n",
      "step 1500, train accuracy 0.941176, train NLL 0.02211\n",
      "test accuracy 0.777778, test NLL 0.0220988\n",
      "RMSE 0.241543\n",
      "KL 0.419953\n",
      "step 0, train accuracy 0.588235, train NLL 0.792025\n",
      "step 1500, train accuracy 1, train NLL 0.0220514\n",
      "test accuracy 0.888889, test NLL 0.0220519\n",
      "RMSE 0.252701\n",
      "KL 0.378883\n",
      "step 0, train accuracy 0.529412, train NLL 0.801\n",
      "step 1500, train accuracy 0.882353, train NLL 0.0217237\n",
      "test accuracy 1, test NLL 0.02171\n",
      "RMSE 0.176684\n",
      "KL 0.20046\n",
      "step 0, train accuracy 0.117647, train NLL 0.799814\n",
      "step 1500, train accuracy 0.941176, train NLL 0.022528\n",
      "test accuracy 0.888889, test NLL 0.0225161\n",
      "RMSE 0.232409\n",
      "KL 0.291882\n",
      "step 0, train accuracy 0.294118, train NLL 0.805276\n",
      "step 1500, train accuracy 0.941176, train NLL 0.0218965\n",
      "test accuracy 0.888889, test NLL 0.0218876\n",
      "RMSE 0.216612\n",
      "KL 0.293721\n",
      "step 0, train accuracy 0.294118, train NLL 0.796496\n",
      "step 1500, train accuracy 0.823529, train NLL 0.0213575\n",
      "test accuracy 1, test NLL 0.0213407\n",
      "RMSE 0.155885\n",
      "KL 0.193884\n",
      "step 0, train accuracy 0.647059, train NLL 0.793719\n",
      "step 1500, train accuracy 1, train NLL 0.0225211\n",
      "test accuracy 0.888889, test NLL 0.02251\n",
      "RMSE 0.243077\n",
      "KL 0.351548\n",
      "step 0, train accuracy 0.294118, train NLL 0.797185\n",
      "step 1500, train accuracy 1, train NLL 0.0224188\n",
      "test accuracy 0.888889, test NLL 0.0224037\n",
      "RMSE 0.162521\n",
      "KL 0.466619\n",
      "step 0, train accuracy 0, train NLL 0.792423\n",
      "step 1500, train accuracy 0.882353, train NLL 0.0232055\n",
      "test accuracy 1, test NLL 0.02319\n",
      "RMSE 0.20209\n",
      "KL 0.272966\n",
      "step 0, train accuracy 0.588235, train NLL 0.79145\n",
      "step 1500, train accuracy 0.941176, train NLL 0.0205702\n",
      "test accuracy 0.777778, test NLL 0.020555\n",
      "RMSE 0.266969\n",
      "KL 0.360124\n",
      "step 0, train accuracy 0.0588235, train NLL 0.797446\n",
      "step 1500, train accuracy 0.941176, train NLL 0.0229923\n",
      "test accuracy 0.777778, test NLL 0.022975\n",
      "RMSE 0.251179\n",
      "KL 0.273491\n",
      "step 0, train accuracy 0.588235, train NLL 0.787558\n",
      "step 1500, train accuracy 1, train NLL 0.0208416\n",
      "test accuracy 1, test NLL 0.0208339\n",
      "RMSE 0.185377\n",
      "KL 0.213534\n",
      "step 0, train accuracy 0.0588235, train NLL 0.795521\n",
      "step 1500, train accuracy 1, train NLL 0.0231496\n",
      "test accuracy 0.888889, test NLL 0.0231404\n",
      "RMSE 0.210697\n",
      "KL 0.312649\n",
      "step 0, train accuracy 0.176471, train NLL 0.800078\n",
      "step 1500, train accuracy 0.941176, train NLL 0.0235665\n",
      "test accuracy 1, test NLL 0.0235596\n",
      "RMSE 0.200111\n",
      "KL 0.253407\n",
      "step 0, train accuracy 0.588235, train NLL 0.787857\n",
      "step 1500, train accuracy 0.882353, train NLL 0.0214654\n",
      "test accuracy 0.888889, test NLL 0.0214509\n",
      "RMSE 0.211847\n",
      "KL 0.28789\n",
      "step 0, train accuracy 0.470588, train NLL 0.787894\n",
      "step 1500, train accuracy 0.823529, train NLL 0.020387\n",
      "test accuracy 0.888889, test NLL 0.0203812\n",
      "RMSE 0.203749\n",
      "KL 0.242848\n",
      "step 0, train accuracy 0.352941, train NLL 0.789884\n",
      "step 1500, train accuracy 0.882353, train NLL 0.0227928\n",
      "test accuracy 0.666667, test NLL 0.0227772\n",
      "RMSE 0.193599\n",
      "KL 0.326638\n",
      "step 0, train accuracy 0.294118, train NLL 0.807236\n",
      "step 1500, train accuracy 0.941176, train NLL 0.0214813\n",
      "test accuracy 1, test NLL 0.0214674\n",
      "RMSE 0.122019\n",
      "KL 0.158755\n",
      "step 0, train accuracy 0.352941, train NLL 0.795081\n",
      "step 1500, train accuracy 0.882353, train NLL 0.0215885\n",
      "test accuracy 0.888889, test NLL 0.0215706\n",
      "RMSE 0.210754\n",
      "KL 0.285987\n",
      "step 0, train accuracy 0.117647, train NLL 0.795461\n",
      "step 1500, train accuracy 0.941176, train NLL 0.0232456\n",
      "test accuracy 0.888889, test NLL 0.0232351\n",
      "RMSE 0.159276\n",
      "KL 0.362593\n",
      "step 0, train accuracy 0.411765, train NLL 0.793259\n",
      "step 1500, train accuracy 0.941176, train NLL 0.0228874\n",
      "test accuracy 1, test NLL 0.0228782\n",
      "RMSE 0.199315\n",
      "KL 0.249885\n",
      "step 0, train accuracy 0.0588235, train NLL 0.803103\n",
      "step 1500, train accuracy 0.941176, train NLL 0.0226983\n",
      "test accuracy 0.777778, test NLL 0.0226812\n",
      "RMSE 0.174352\n",
      "KL 0.277102\n",
      "step 0, train accuracy 0, train NLL 0.801484\n",
      "step 1500, train accuracy 1, train NLL 0.0221769\n",
      "test accuracy 0.666667, test NLL 0.022166\n",
      "RMSE 0.273096\n",
      "KL 0.294233\n",
      "step 0, train accuracy 0.588235, train NLL 0.793796\n",
      "step 1500, train accuracy 0.941176, train NLL 0.0220564\n",
      "test accuracy 1, test NLL 0.0220482\n",
      "RMSE 0.177834\n",
      "KL 0.296357\n",
      "step 0, train accuracy 0.352941, train NLL 0.792332\n",
      "step 1500, train accuracy 1, train NLL 0.0224789\n",
      "test accuracy 1, test NLL 0.0224694\n",
      "RMSE 0.151993\n",
      "KL 0.153036\n",
      "step 0, train accuracy 0.411765, train NLL 0.802729\n",
      "step 1500, train accuracy 0.823529, train NLL 0.0171886\n",
      "test accuracy 0.666667, test NLL 0.0171729\n",
      "RMSE 0.369035\n",
      "KL 0.435327\n",
      "step 0, train accuracy 0.470588, train NLL 0.802667\n",
      "step 1500, train accuracy 0.823529, train NLL 0.0236627\n",
      "test accuracy 1, test NLL 0.0236457\n",
      "RMSE 0.123806\n",
      "KL 0.183888\n",
      "step 0, train accuracy 0.235294, train NLL 0.796619\n",
      "step 1500, train accuracy 0.823529, train NLL 0.0171489\n",
      "test accuracy 0.777778, test NLL 0.0171358\n",
      "RMSE 0.346729\n",
      "KL 0.455196\n",
      "step 0, train accuracy 0.0588235, train NLL 0.803744\n",
      "step 1500, train accuracy 0.941176, train NLL 0.0222641\n",
      "test accuracy 0.777778, test NLL 0.0222486\n",
      "RMSE 0.232808\n",
      "KL 0.351974\n",
      "step 0, train accuracy 0.176471, train NLL 0.785546\n",
      "step 1500, train accuracy 0.941176, train NLL 0.0221593\n",
      "test accuracy 0.777778, test NLL 0.0221432\n",
      "RMSE 0.29806\n",
      "KL 0.383969\n",
      "step 0, train accuracy 0, train NLL 0.793156\n",
      "step 1500, train accuracy 0.882353, train NLL 0.0212806\n",
      "test accuracy 1, test NLL 0.0212718\n",
      "RMSE 0.160371\n",
      "KL 0.212236\n",
      "step 0, train accuracy 0.0588235, train NLL 0.800227\n",
      "step 1500, train accuracy 1, train NLL 0.0233226\n",
      "test accuracy 0.888889, test NLL 0.0233083\n",
      "RMSE 0.283241\n",
      "KL 0.316149\n",
      "step 0, train accuracy 0.529412, train NLL 0.796675\n",
      "step 1500, train accuracy 0.882353, train NLL 0.0234544\n",
      "test accuracy 0.888889, test NLL 0.0234448\n",
      "RMSE 0.26253\n",
      "KL 0.420439\n",
      "step 0, train accuracy 0.176471, train NLL 0.800225\n",
      "step 1500, train accuracy 0.941176, train NLL 0.0227547\n",
      "test accuracy 0.888889, test NLL 0.0227386\n",
      "RMSE 0.192658\n",
      "KL 0.245941\n",
      "step 0, train accuracy 0.470588, train NLL 0.795375\n",
      "step 1500, train accuracy 1, train NLL 0.0211284\n",
      "test accuracy 1, test NLL 0.0211156\n",
      "RMSE 0.165639\n",
      "KL 0.236917\n",
      "step 0, train accuracy 0.176471, train NLL 0.810139\n",
      "step 1500, train accuracy 0.882353, train NLL 0.0216122\n",
      "test accuracy 0.777778, test NLL 0.0216014\n",
      "RMSE 0.203184\n",
      "KL 0.166644\n",
      "step 0, train accuracy 0, train NLL 0.796126\n",
      "step 1500, train accuracy 1, train NLL 0.0215389\n",
      "test accuracy 0.777778, test NLL 0.0215255\n",
      "RMSE 0.219597\n",
      "KL 0.495542\n",
      "step 0, train accuracy 0.117647, train NLL 0.800025\n",
      "step 1500, train accuracy 0.941176, train NLL 0.0232011\n",
      "test accuracy 0.888889, test NLL 0.0231919\n",
      "RMSE 0.194644\n",
      "KL 0.412873\n",
      "step 0, train accuracy 0, train NLL 0.794243\n",
      "step 1500, train accuracy 0.882353, train NLL 0.022698\n",
      "test accuracy 0.777778, test NLL 0.0226794\n",
      "RMSE 0.222536\n",
      "KL 0.448782\n",
      "step 0, train accuracy 0.588235, train NLL 0.799017\n",
      "step 1500, train accuracy 0.882353, train NLL 0.022654\n",
      "test accuracy 1, test NLL 0.022642\n",
      "RMSE 0.240889\n",
      "KL 0.36222\n",
      "step 0, train accuracy 0, train NLL 0.78305\n",
      "step 1500, train accuracy 0.823529, train NLL 0.0212056\n",
      "test accuracy 1, test NLL 0.0211924\n",
      "RMSE 0.120426\n",
      "KL 0.109013\n",
      "step 0, train accuracy 0.352941, train NLL 0.790855\n",
      "step 1500, train accuracy 0.823529, train NLL 0.0221397\n",
      "test accuracy 0.666667, test NLL 0.0221202\n",
      "RMSE 0.257815\n",
      "KL 0.408442\n",
      "step 0, train accuracy 0.117647, train NLL 0.805122\n",
      "step 1500, train accuracy 0.764706, train NLL 0.0227071\n",
      "test accuracy 1, test NLL 0.0226899\n",
      "RMSE 0.192851\n",
      "KL 0.272916\n",
      "step 0, train accuracy 0.529412, train NLL 0.80587\n",
      "step 1500, train accuracy 1, train NLL 0.0229886\n",
      "test accuracy 0.777778, test NLL 0.0229751\n",
      "RMSE 0.184649\n",
      "KL 0.521208\n",
      "step 0, train accuracy 0.0588235, train NLL 0.797118\n",
      "step 1500, train accuracy 0.823529, train NLL 0.021837\n",
      "test accuracy 0.888889, test NLL 0.0218254\n",
      "RMSE 0.197566\n",
      "KL 0.184271\n",
      "step 0, train accuracy 0.411765, train NLL 0.799992\n",
      "step 1500, train accuracy 0.823529, train NLL 0.0208932\n",
      "test accuracy 0.888889, test NLL 0.0208853\n",
      "RMSE 0.231731\n",
      "KL 0.291321\n",
      "step 0, train accuracy 0.294118, train NLL 0.796935\n",
      "step 1500, train accuracy 0.882353, train NLL 0.0221602\n",
      "test accuracy 0.888889, test NLL 0.0221468\n",
      "RMSE 0.218429\n",
      "KL 0.279364\n",
      "step 0, train accuracy 0.0588235, train NLL 0.794831\n",
      "step 1500, train accuracy 0.941176, train NLL 0.0220863\n",
      "test accuracy 0.777778, test NLL 0.0220847\n",
      "RMSE 0.219301\n",
      "KL 0.253844\n",
      "step 0, train accuracy 0.470588, train NLL 0.799453\n",
      "step 1500, train accuracy 0.823529, train NLL 0.0218772\n",
      "test accuracy 0.888889, test NLL 0.0218718\n",
      "RMSE 0.240317\n",
      "KL 0.28033\n",
      "step 0, train accuracy 0.294118, train NLL 0.795382\n",
      "step 1500, train accuracy 0.941176, train NLL 0.0218006\n",
      "test accuracy 1, test NLL 0.0217986\n",
      "RMSE 0.218587\n",
      "KL 0.33612\n",
      "step 0, train accuracy 0.588235, train NLL 0.794649\n",
      "step 1500, train accuracy 0.941176, train NLL 0.0209392\n",
      "test accuracy 1, test NLL 0.0209272\n",
      "RMSE 0.150334\n",
      "KL 0.155114\n",
      "step 0, train accuracy 0.647059, train NLL 0.793466\n",
      "step 1500, train accuracy 0.941176, train NLL 0.0226004\n",
      "test accuracy 1, test NLL 0.0225947\n",
      "RMSE 0.229111\n",
      "KL 0.28823\n",
      "step 0, train accuracy 0, train NLL 0.79057\n",
      "step 1500, train accuracy 0.941176, train NLL 0.021634\n",
      "test accuracy 0.888889, test NLL 0.0216237\n",
      "RMSE 0.196363\n",
      "KL 0.236989\n",
      "step 0, train accuracy 0.352941, train NLL 0.786147\n",
      "step 1500, train accuracy 0.941176, train NLL 0.0213319\n",
      "test accuracy 0.777778, test NLL 0.0213235\n",
      "RMSE 0.199194\n",
      "KL 0.243641\n",
      "step 0, train accuracy 0.647059, train NLL 0.805795\n",
      "step 1500, train accuracy 0.941176, train NLL 0.0232437\n",
      "test accuracy 1, test NLL 0.0232285\n",
      "RMSE 0.208479\n",
      "KL 0.228264\n",
      "step 0, train accuracy 0.235294, train NLL 0.804386\n",
      "step 1500, train accuracy 0.941176, train NLL 0.024092\n",
      "test accuracy 0.888889, test NLL 0.0240842\n",
      "RMSE 0.222025\n",
      "KL 0.321394\n",
      "step 0, train accuracy 0.176471, train NLL 0.802697\n",
      "step 1500, train accuracy 0.882353, train NLL 0.0216841\n",
      "test accuracy 0.888889, test NLL 0.0216594\n",
      "RMSE 0.224482\n",
      "KL 0.230213\n",
      "step 0, train accuracy 0.0588235, train NLL 0.798342\n",
      "step 1500, train accuracy 0.941176, train NLL 0.0215892\n",
      "test accuracy 0.777778, test NLL 0.0215824\n",
      "RMSE 0.253306\n",
      "KL 0.303378\n",
      "step 0, train accuracy 0.705882, train NLL 0.787564\n",
      "step 1500, train accuracy 0.823529, train NLL 0.0198827\n",
      "test accuracy 0.888889, test NLL 0.0198693\n",
      "RMSE 0.219093\n",
      "KL 0.288139\n",
      "step 0, train accuracy 0, train NLL 0.798955\n",
      "step 1500, train accuracy 0.941176, train NLL 0.022291\n",
      "test accuracy 0.777778, test NLL 0.0222805\n",
      "RMSE 0.285198\n",
      "KL 0.381289\n",
      "step 0, train accuracy 0.294118, train NLL 0.801543\n",
      "step 1500, train accuracy 0.882353, train NLL 0.0211946\n",
      "test accuracy 0.777778, test NLL 0.0211806\n",
      "RMSE 0.212781\n",
      "KL 0.290081\n",
      "step 0, train accuracy 0.0588235, train NLL 0.790253\n",
      "step 1500, train accuracy 0.882353, train NLL 0.0208226\n",
      "test accuracy 0.777778, test NLL 0.0208133\n",
      "RMSE 0.222042\n",
      "KL 0.216265\n",
      "step 0, train accuracy 0.294118, train NLL 0.79592\n",
      "step 1500, train accuracy 1, train NLL 0.0228326\n",
      "test accuracy 0.777778, test NLL 0.0228183\n",
      "RMSE 0.215804\n",
      "KL 0.24499\n",
      "step 0, train accuracy 0.235294, train NLL 0.800682\n",
      "step 1500, train accuracy 0.941176, train NLL 0.0232861\n",
      "test accuracy 1, test NLL 0.0232737\n",
      "RMSE 0.182059\n",
      "KL 0.18854\n",
      "step 0, train accuracy 0.117647, train NLL 0.794803\n",
      "step 1500, train accuracy 0.882353, train NLL 0.021903\n",
      "test accuracy 0.888889, test NLL 0.02189\n",
      "RMSE 0.195361\n",
      "KL 0.147534\n",
      "step 0, train accuracy 0.529412, train NLL 0.794017\n",
      "step 1500, train accuracy 0.882353, train NLL 0.02282\n",
      "test accuracy 1, test NLL 0.0228123\n",
      "RMSE 0.195248\n",
      "KL 0.288389\n",
      "step 0, train accuracy 0.529412, train NLL 0.7951\n",
      "step 1500, train accuracy 1, train NLL 0.0221126\n",
      "test accuracy 1, test NLL 0.0220951\n",
      "RMSE 0.166514\n",
      "KL 0.257648\n",
      "step 0, train accuracy 0.176471, train NLL 0.810866\n",
      "step 1500, train accuracy 1, train NLL 0.022341\n",
      "test accuracy 0.777778, test NLL 0.0223281\n",
      "RMSE 0.286346\n",
      "KL 0.377402\n",
      "step 0, train accuracy 0.588235, train NLL 0.805883\n",
      "step 1500, train accuracy 0.882353, train NLL 0.0208884\n",
      "test accuracy 1, test NLL 0.0208859\n",
      "RMSE 0.212915\n",
      "KL 0.206811\n",
      "step 0, train accuracy 0.588235, train NLL 0.791426\n",
      "step 1500, train accuracy 1, train NLL 0.0229006\n",
      "test accuracy 0.888889, test NLL 0.0228861\n",
      "RMSE 0.205261\n",
      "KL 0.292907\n",
      "step 0, train accuracy 0.529412, train NLL 0.796191\n",
      "step 1500, train accuracy 0.941176, train NLL 0.023229\n",
      "test accuracy 1, test NLL 0.0232108\n",
      "RMSE 0.218522\n",
      "KL 0.289086\n",
      "step 0, train accuracy 0.0588235, train NLL 0.796364\n",
      "step 1500, train accuracy 1, train NLL 0.0223889\n",
      "test accuracy 0.777778, test NLL 0.0223767\n",
      "RMSE 0.266213\n",
      "KL 0.368219\n",
      "step 0, train accuracy 0.235294, train NLL 0.78977\n",
      "step 1500, train accuracy 0.941176, train NLL 0.0227969\n",
      "test accuracy 1, test NLL 0.0227797\n",
      "RMSE 0.220127\n",
      "KL 0.251459\n",
      "step 0, train accuracy 0.117647, train NLL 0.804577\n",
      "step 1500, train accuracy 1, train NLL 0.0240922\n",
      "test accuracy 0.888889, test NLL 0.0240842\n",
      "RMSE 0.260929\n",
      "KL 0.344307\n",
      "step 0, train accuracy 0.411765, train NLL 0.815656\n",
      "step 1500, train accuracy 0.941176, train NLL 0.0235431\n",
      "test accuracy 0.888889, test NLL 0.0235327\n",
      "RMSE 0.239132\n",
      "KL 0.476201\n",
      "step 0, train accuracy 0.470588, train NLL 0.797807\n",
      "step 1500, train accuracy 0.941176, train NLL 0.0201964\n",
      "test accuracy 0.777778, test NLL 0.0201845\n",
      "RMSE 0.222017\n",
      "KL 4.7024\n",
      "step 0, train accuracy 0.235294, train NLL 0.792965\n",
      "step 1500, train accuracy 0.941176, train NLL 0.0216344\n",
      "test accuracy 0.888889, test NLL 0.0216192\n",
      "RMSE 0.239782\n",
      "KL 0.328723\n",
      "step 0, train accuracy 0.352941, train NLL 0.794705\n",
      "step 1500, train accuracy 0.882353, train NLL 0.0210209\n",
      "test accuracy 1, test NLL 0.0210058\n",
      "RMSE 0.16337\n",
      "KL 0.199882\n",
      "step 0, train accuracy 0.588235, train NLL 0.804854\n",
      "step 1500, train accuracy 0.941176, train NLL 0.023868\n",
      "test accuracy 0.888889, test NLL 0.0238566\n",
      "RMSE 0.175236\n",
      "KL 0.426152\n",
      "step 0, train accuracy 0.117647, train NLL 0.799532\n",
      "step 1500, train accuracy 0.941176, train NLL 0.0223403\n",
      "test accuracy 1, test NLL 0.0223299\n",
      "RMSE 0.262417\n",
      "KL 0.425152\n",
      "step 0, train accuracy 0.823529, train NLL 0.788727\n",
      "step 1500, train accuracy 1, train NLL 0.0225244\n",
      "test accuracy 1, test NLL 0.022516\n",
      "RMSE 0.221538\n",
      "KL 0.274055\n",
      "step 0, train accuracy 0.235294, train NLL 0.794651\n",
      "step 1500, train accuracy 1, train NLL 0.0227966\n",
      "test accuracy 0.888889, test NLL 0.0227931\n",
      "RMSE 0.240385\n",
      "KL 0.355584\n",
      "step 0, train accuracy 0.235294, train NLL 0.799326\n",
      "step 1500, train accuracy 1, train NLL 0.0221883\n",
      "test accuracy 1, test NLL 0.0221772\n",
      "RMSE 0.147195\n",
      "KL 0.175515\n",
      "step 0, train accuracy 0.235294, train NLL 0.799157\n",
      "step 1500, train accuracy 0.882353, train NLL 0.0229496\n",
      "test accuracy 1, test NLL 0.0229365\n",
      "RMSE 0.167624\n",
      "KL 0.18812\n",
      "step 0, train accuracy 0.176471, train NLL 0.793589\n",
      "step 1500, train accuracy 0.941176, train NLL 0.0204517\n",
      "test accuracy 0.666667, test NLL 0.0204427\n",
      "RMSE 0.285506\n",
      "KL 0.44646\n",
      "step 0, train accuracy 0.588235, train NLL 0.797441\n",
      "step 1500, train accuracy 1, train NLL 0.0220969\n",
      "test accuracy 0.777778, test NLL 0.0220897\n",
      "RMSE 0.238681\n",
      "KL 0.373138\n",
      "step 0, train accuracy 0, train NLL 0.807969\n",
      "step 1500, train accuracy 0.941176, train NLL 0.0226877\n",
      "test accuracy 1, test NLL 0.0226832\n",
      "RMSE 0.176017\n",
      "KL 0.233046\n",
      "step 0, train accuracy 0.764706, train NLL 0.796039\n",
      "step 1500, train accuracy 0.705882, train NLL 0.0156617\n",
      "test accuracy 0.444444, test NLL 0.0156517\n",
      "RMSE 0.377695\n",
      "KL 0.583505\n",
      "step 0, train accuracy 0.117647, train NLL 0.804202\n",
      "step 1500, train accuracy 0.941176, train NLL 0.0227177\n",
      "test accuracy 0.888889, test NLL 0.0227102\n",
      "RMSE 0.276886\n",
      "KL 0.309725\n",
      "step 0, train accuracy 0.0588235, train NLL 0.803287\n",
      "step 1500, train accuracy 0.882353, train NLL 0.0229247\n",
      "test accuracy 1, test NLL 0.0229098\n",
      "RMSE 0.149184\n",
      "KL 0.229602\n",
      "step 0, train accuracy 0.470588, train NLL 0.798457\n",
      "step 1500, train accuracy 0.823529, train NLL 0.021093\n",
      "test accuracy 1, test NLL 0.0210799\n",
      "RMSE 0.24011\n",
      "KL 0.35523\n",
      "step 0, train accuracy 0.470588, train NLL 0.800706\n",
      "step 1500, train accuracy 1, train NLL 0.0238515\n",
      "test accuracy 0.888889, test NLL 0.0238382\n",
      "RMSE 0.192203\n",
      "KL 0.447669\n",
      "step 0, train accuracy 0.411765, train NLL 0.789118\n",
      "step 1500, train accuracy 1, train NLL 0.0213504\n",
      "test accuracy 0.888889, test NLL 0.0213405\n",
      "RMSE 0.231974\n",
      "KL 0.468965\n",
      "step 0, train accuracy 0.176471, train NLL 0.790252\n",
      "step 1500, train accuracy 0.941176, train NLL 0.0222861\n",
      "test accuracy 0.888889, test NLL 0.0222783\n",
      "RMSE 0.197607\n",
      "KL 0.320013\n",
      "step 0, train accuracy 0.235294, train NLL 0.803321\n",
      "step 1500, train accuracy 0.882353, train NLL 0.0221212\n",
      "test accuracy 0.888889, test NLL 0.0221121\n",
      "RMSE 0.263162\n",
      "KL 0.435044\n",
      "step 0, train accuracy 0.529412, train NLL 0.799554\n",
      "step 1500, train accuracy 1, train NLL 0.0232656\n",
      "test accuracy 1, test NLL 0.0232436\n",
      "RMSE 0.219294\n",
      "KL 0.356683\n"
     ]
    }
   ],
   "source": [
    "timetime = time.time()\n",
    "test_accuracy_all = np.zeros([10,10])\n",
    "test_NLL_all = np.zeros([10,10])\n",
    "test_RMSE_all = np.zeros([10,10])\n",
    "test_KLadhoc_all = np.zeros([10,10])\n",
    "for k in range(1,11):    \n",
    "    for j in range(1,11):\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        shuffle = np.random.permutation(range(inputs_row.shape[0]))\n",
    "        index_train = np.concatenate([shuffle[0:inputs_row.shape[0]//10*(j-1)], \n",
    "                              shuffle[inputs_row.shape[0]//10*j:inputs_row.shape[0]]]) \n",
    "        index_tests = shuffle[inputs_row.shape[0]//10*(j-1):inputs_row.shape[0]//10*j]\n",
    "        inputs_row_train = inputs_row[index_train]\n",
    "        inputs_col_train = inputs_col[index_train]\n",
    "        target_row_train = target_row[index_train]\n",
    "        inputs_row_tests = inputs_row[index_tests]\n",
    "        inputs_col_tests = inputs_col[index_tests]\n",
    "        target_row_tests = target_row[index_tests]\n",
    "        for i in range(1501):\n",
    "            if i%5 == 0:\n",
    "                perm_train = np.random.permutation(range(inputs_row_train.shape[0]))\n",
    "            inputs_row_train_batch = inputs_row_train[perm_train[perm_train.shape[0]//5*(i%5):perm_train.shape[0]//5*(i%5+1)]]\n",
    "            inputs_col_train_batch = inputs_col_train[perm_train[perm_train.shape[0]//5*(i%5):perm_train.shape[0]//5*(i%5+1)]]\n",
    "            target_row_train_batch = target_row_train[perm_train[perm_train.shape[0]//5*(i%5):perm_train.shape[0]//5*(i%5+1)]]\n",
    "            if i%1500 == 0:\n",
    "                train_accuracy = accuracy.eval(feed_dict={\n",
    "                        x_row: inputs_row_train_batch,\n",
    "                        x_col: inputs_col_train_batch,\n",
    "                        y_: target_row_train_batch, \n",
    "                        keep_prob: 1.0,\n",
    "                        keep_prob_col: 1.0})\n",
    "                train_NLL = cross_entropy.eval(feed_dict={\n",
    "                        x_row: inputs_row_train_batch, \n",
    "                        x_col: inputs_col_train_batch,\n",
    "                        y_: target_row_train_batch,\n",
    "                        keep_prob: 1.0,\n",
    "                        keep_prob_col: 1.0})\n",
    "                print(\"step %d, train accuracy %g, train NLL %g\"%(i, train_accuracy, train_NLL))\n",
    "            train_step.run(feed_dict={x_row: inputs_row_train_batch, \n",
    "                                      x_col: inputs_col_train_batch, \n",
    "                                      y_: target_row_train_batch, \n",
    "                                      keep_prob: 0.8,\n",
    "                                      keep_prob_col: 0.8})\n",
    "        test_accuracy = accuracy.eval(feed_dict={\n",
    "            x_row: inputs_row_tests,\n",
    "            x_col: inputs_col_tests,\n",
    "            y_: target_row_tests, \n",
    "            keep_prob: 1.0,\n",
    "            keep_prob_col: 1.0})\n",
    "        test_NLL = cross_entropy.eval(feed_dict={\n",
    "            x_row: inputs_row_tests,\n",
    "            x_col: inputs_col_tests,\n",
    "            y_: target_row_tests, \n",
    "            keep_prob: 1.0,\n",
    "            keep_prob_col: 1.0})\n",
    "        print(\"test accuracy %g, test NLL %g\"%(test_accuracy, test_NLL))\n",
    "        test_accuracy_all[j-1][k-1] = test_accuracy\n",
    "        test_NLL_all[j-1][k-1] = test_NLL\n",
    "        compare_y = y.eval(feed_dict={\n",
    "                            x_row: inputs_row_tests, \n",
    "                            x_col: inputs_col_tests, \n",
    "                            y_: target_row_tests, \n",
    "                            keep_prob: 1.0, \n",
    "                            keep_prob_col: 1.0})\n",
    "        compare_y = compare_y.reshape(compare_y.shape[0], compare_y.shape[1])\n",
    "        compare_y_ = y_.eval(feed_dict={\n",
    "                                x_row: inputs_row_tests,\n",
    "                                x_col: inputs_col_tests,\n",
    "                                y_: target_row_tests, \n",
    "                                keep_prob: 1.0,\n",
    "                                keep_prob_col: 1.0})\n",
    "        compare_y_ = compare_y_.reshape(compare_y_.shape[0], compare_y_.shape[1])\n",
    "        compare = pd.DataFrame(np.concatenate((compare_y, compare_y_), axis=1))\n",
    "        compare.columns = [\"y1\",\"y2\",\"y3\",\"y_1\",\"y_2\",\"y_3\"]\n",
    "        compare['RMSE 1'] = (compare['y1'] - compare['y_1'])**2\n",
    "        compare['RMSE 2'] = (compare['y2'] - compare['y_2'])**2\n",
    "        compare['RMSE 3'] = (compare['y3'] - compare['y_3'])**2\n",
    "        RMSE = np.sqrt((compare['RMSE 1'] + compare['RMSE 2'] + compare['RMSE 3']).sum()/(compare['RMSE 1'].shape[0]*3))\n",
    "        print(\"RMSE %g\"%(RMSE))\n",
    "        test_RMSE_all[j-1][k-1] = RMSE\n",
    "        KL_adhoc_tmp = np.zeros(compare.shape[0])\n",
    "        for l in range(compare.shape[0]):\n",
    "            KLy_y = sp.stats.entropy([compare.loc[l]['y_1'], compare.loc[l]['y_2'], compare.loc[l]['y_3']],\n",
    "                            [compare.loc[l]['y1'], compare.loc[l]['y2'], compare.loc[l]['y3']])\n",
    "            KLuniformy = sp.stats.entropy([1/3, 1/3, 1/3],\n",
    "                            [compare.loc[l]['y1'], compare.loc[l]['y2'], compare.loc[l]['y3']])\n",
    "            KL_adhoc_tmp[l] = KLy_y/KLuniformy\n",
    "        KLadhoc = np.mean(KL_adhoc_tmp)\n",
    "        print(\"KL %g\"%(KLadhoc))\n",
    "        test_KLadhoc_all[j-1][k-1] = KLadhoc\n",
    "elapsedtime = time.time() - timetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time 22.2861 min\n",
      "test accuracy mean 0.883333\n",
      "test accuracy variance 0.0119444\n",
      "test NLL mean 0.0220452\n",
      "test NLL variance 1.75304e-06\n",
      "test RMSE mean 0.219372\n",
      "test RMSE variance 0.00224954\n",
      "test KL mean 0.357586\n",
      "test KL variance 0.201006\n"
     ]
    }
   ],
   "source": [
    "print(\"elapsed time %g min\"%(elapsedtime/60))\n",
    "print(\"test accuracy mean %g\"%(np.mean(test_accuracy_all)))\n",
    "print(\"test accuracy variance %g\"%(np.var(test_accuracy_all)))\n",
    "print(\"test NLL mean %g\"%(np.mean(test_NLL_all)))\n",
    "print(\"test NLL variance %g\"%(np.var(test_NLL_all)))\n",
    "print(\"test RMSE mean %g\"%(np.mean(test_RMSE_all)))\n",
    "print(\"test RMSE variance %g\"%(np.var(test_RMSE_all)))\n",
    "print(\"test KL mean %g\"%(np.mean(test_KLadhoc_all)))\n",
    "print(\"test KL variance %g\"%(np.var(test_KLadhoc_all)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
